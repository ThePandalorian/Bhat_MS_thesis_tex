\epigraph{\justifying Somewhere [...] between the specific that has no meaning and the general that has no content there must be, for each purpose and at each level of abstraction, an optimum degree of generality}{Kenneth Boulding~\citep{boulding_general_1956}}

Let us now consider a slightly more complicated scenario. Assume that our population is \emph{not} composed of identical organisms, but instead can contain up to $m$ different kinds of organisms - For example, individuals may come in one of $m$ colors, or a gene may have $m$ different alleles. The specific interpretation of the different variants is irrelevant to our formalism, and I, therefore, refer to each distinct variant of an organism simply as a `type'. Unlike many classic stochastic formulations in evolutionary theory~\citep{fisher_genetical_1930,wright_evolution_1931,moran_random_1958,crow_introduction_1970, lande_natural_1976}, I do not assume a fixed (effective) population size and instead allow the total population size to fluctuate naturally over time. 

\section{Description of the process and the Master Equation}
Given a population that can contain up to $m$ different (fixed) kinds of organisms, it can be entirely characterized by specifying the number of organisms of each type (Figure \ref{fig_nD_pop_description}A). Thus, the state of the population at a given time $t$ is an $m$-dimensional \emph{vector} of the form $\mathbf{n}(t) = [n_1(t),n_2(t),\ldots,n_m(t)]$, where $n_i(t)$ is the number of individuals of type $i$ in the population at time $t$.

Given a state $\mathbf{n}(t)$,  we also need to describe how this vector can change over time due to births and deaths (ecology). In this case, a birth or death could result in an individual belonging to one of $m$ different types. Thus, whereas before we had two functions $b(n)$ and $d(n)$ which take in a number as an input, we now require $2m$ functions that take in a vector as an input (Figure \ref{fig_nD_pop_description}B). In other words, for each type $i \in \{1,2,\ldots,m\}$, we must specify a birth rate $b_i(\mathbf{n})$ and a death rate $d_i(\mathbf{n})$. By `rates', we mean that if we know that \emph{either a birth or a death} occurs, then the probability that this event is the birth of an individual of type $i$ is given by
\begin{equation*}
\mathbb{P}\big[\textrm{ Birth of a type $i$ individual } \big{|} \textrm{ something happened }\big] = \frac{b_i(\mathbf{n})}{\sum\limits_{j=1}^{m}(b_j(\mathbf{n})+d_j(\mathbf{n}))}
\end{equation*}
and the probability that the event is the death of an individual of type $i$ is
\begin{equation*}
\mathbb{P}\big[\textrm{ Death of a type $i$ individual } \big{|} \textrm{ something happened }\big] = \frac{d_i(\mathbf{n})}{\sum\limits_{j=1}^{m}(b_j(\mathbf{n})+d_j(\mathbf{n}))}
\end{equation*}

\myfig{0.9}{figures/3.1_BD_process_2D.png}{\textbf{Schematic description of a multi-dimensional birth-death process}. \textbf{(A)} Consider a population of birds in which individuals are either {\color{red}red} or {\color{blue}blue}. In this case, we have $m=2$, since there are two types of individuals in the population. \textbf{(B)} The state of the system can be described by a vector containing the number of individuals of each discrete type (in this case, the number of red and blue birds in the population). Births and deaths result in changes in the elements of the state vector.}{fig_nD_pop_description}

As before, we can describe the rate of change of $P(\mathbf{n},t)$, the probability of finding the population in a state $\mathbf{n}$ at time $t$, by measuring the inflow and outflow rates. Since the population changes in units of exactly one individual (by definition of a birth-death process; see section \ref{sec_math_background}), we know that these inflow and outflow rates must only involve populations that are a single individual away from our focal population. In other words, for a population $\mathbf{n} = [n_1,\ldots,n_{m}]$, the `inflow' is from all populations of the form $[n_1,\ldots,n_{i}-1,\dots,n_{m}]$ through a birth of a type $i$ individual, and from all populations of the form $[n_1,\ldots,n_{i}+1,\dots,n_{m}]$ through the death of a type $i$ individual. Thus, we have the inflow rate
\begin{equation}
\label{nD_rate_in}
\begin{split}
R_{\textrm{in}}(\mathbf{n},t) &= \sum\limits_{j=1}^{m}b_{j}([n_1,\ldots,n_{j}-1,\ldots,n_m])P([n_1,\ldots,n_{j}-1,\ldots,n_m],t) \\
& +\sum\limits_{j=1}^{m}d_{j}([n_1,\ldots,n_{j}+1,\ldots,n_m])P([n_1,\ldots,n_{j}+1,\ldots,n_m],t)
\end{split}
\end{equation}
Outflow is through births and deaths of individuals in the population $\mathbf{n}$ itself, and thus we have:
\begin{equation}
\label{nD_rate_out}
R_{\textrm{out}}(\mathbf{n},t) = \sum\limits_{j=1}^{m}b_{j}(\mathbf{n})P(\mathbf{n},t) + \sum\limits_{j=1}^{m}d_{j}(\mathbf{n})P(\mathbf{n},t)
\end{equation}
As before, we now define step operators, both for notational ease and in anticipation of the system size expansion. Note that now, we need $2m$ step operators. For each $i \in \{1,\ldots,m\}$, let us define two step operators $\mathcal{E}_{i}^{\pm}$ by their action on any function $f([n_1,\ldots,n_m],t)$ as:
\begin{equation}
\label{nD_step_operators}
\mathcal{E}_{i}^{\pm}f([n_1,\ldots,n_m],t) = f([n_1,\ldots,n_i \pm 1, \ldots n_m],t)
\end{equation}
In other words, $\mathcal{E}_{i}^{\pm}$ just changes the population through the addition or removal of one type $i$ individual. We can now the rate of change of $P(\mathbf{n},t)$ as
\begin{equation}
\frac{\partial P}{\partial t}(\mathbf{n},t) = R_{\textrm{in}}(\mathbf{n},t) - R_{\textrm{out}}(\mathbf{n},t)
\end{equation}
Substituting \eqref{nD_rate_in}, \eqref{nD_rate_out}, and \eqref{nD_step_operators}, we obtain:
\begin{equation}
\label{nD_M_eqn}
\frac{\partial P}{\partial t}(\mathbf{n},t) = \sum\limits_{j=1}^{m}\left[(\mathcal{E}_j^{-}-1)b_j(\mathbf{n})P(\mathbf{n},t) + (\mathcal{E}_j^{+}-1)d_j(\mathbf{n})P(\mathbf{n},t)\right]
\end{equation}
This is the master equation of our $m$-dimensional process.

\section{The system-size expansion}
As before, we now assume we can find a system size parameter $K > 0$ such that we can make the substitutions
\begin{align*}
\mathbf{x} &= \frac{\mathbf{n}}{K}\\
b^{(K)}_i(\mathbf{x}) &= \frac{1}{K}b_i(\mathbf{n})\\
d^{(K)}_i(\mathbf{x}) &= \frac{1}{K}d_i(\mathbf{n})
\end{align*}
and define new step operators $\Delta_{i}^{\pm}$ by their action on any real-valued function $f(\mathbf{x},t)$ as
\begin{equation}
\label{nD_step_operators_rescaled}
\Delta_{i}^{\pm}f([x_1,\ldots,x_m],t) = f([x_1,\ldots,x_i \pm \frac{1}{K}, \ldots x_m],t)
\end{equation}
In terms of these new variables, \eqref{nD_M_eqn} becomes
\begin{equation}
\label{nd_M_eqn_rescaled}
\frac{\partial P}{\partial t}(\mathbf{x},t) = K\sum\limits_{j=1}^{m}\left[(\Delta_j^{-}-1)b^{(K)}_j(\mathbf{x})P(\mathbf{x},t) + (\Delta_j^{+}-1)d^{(K)}_j(\mathbf{x})P(\mathbf{x},t)\right]
\end{equation}
If $K$ is large, we can once again Taylor expand the action of the step operators as
\begin{equation*}
f([x_1,\ldots,x_i \pm \frac{1}{K}, \ldots x_m],t) = f(\mathbf{x},t) \pm \frac{1}{K}\frac{\partial f}{\partial x_i}(\mathbf{x},t) + \frac{1}{2K^2}\frac{\partial^2f}{\partial x_i^2}(\mathbf{x},t) + \mathcal{O}(K^{-3})
\end{equation*}
which, after substituting into \eqref{nd_M_eqn_rescaled}, yields the equation
\begin{equation}
\label{nD_FPE}
\setlength{\fboxsep}{2\fboxsep}\boxed{\frac{\partial P}{\partial t}(\mathbf{x},t) = \sum\limits_{j=1}^{m}\left[-\frac{\partial}{\partial x_j}\{A_j^{-}(\mathbf{x})P(\mathbf{x},t)\} + \frac{1}{2K}\frac{\partial^2}{\partial x_j^2}\{A_j^{+}(\mathbf{x})P(\mathbf{x},t)\}\right]}
\end{equation}
where
\begin{equation*}
A_{i}^{\pm}(\mathbf{x}) = b^{(K)}_i(\mathbf{x})\pm d^{(K)}_i(\mathbf{x})
\end{equation*}
Equation \eqref{nD_FPE} is an $m$-dimensional Fokker-Planck equation, and corresponds to the $m$-dimensional It\^o process
\begin{equation}
\label{nD_Ito_SDE}
d\mathbf{X}_{t} = \mathbf{A^-}(\mathbf{X}_t)dt + \frac{1}{\sqrt{K}}\mathbf{D}(\mathbf{X}_t)d\mathbf{W}_t
\end{equation}
where $\mathbf{A^-}(\mathbf{X}_t)$ is the $m$ dimensional `drift vector' with $i$\textsuperscript{th} element $ = A^{-}_{i}(\mathbf{X}_t)$. $\mathbf{D}(\mathbf{X}_t)$ is the $m \times m$ `diffusion matrix' with $ij$th element $\left(\mathbf{D}(\mathbf{X}_t)\right)_{ij} = \delta_{ij}\left(A^{+}_{i}A^{+}_{j}\right)^{\frac{1}{4}}$, where $\delta_{ij}$ is the Kronecker delta symbol, defined by
\begin{equation*}
\delta_{ij} = 
\begin{cases}
1 & i=j\\
0 & i\neq j
\end{cases}
\end{equation*}
Finally, $\mathbf{W}_t$ is the $m$-dimensional Wiener process and can be thought of as a vector of independent one-dimensional Wiener processes (which have been defined in \ref{intro_SDE}). This is the `mesoscopic' description of our process.

\section{Functional forms of the birth and death rates}

We assume that the birth and death rate functions have the functional form
\begin{equation}
\label{nD_functional_forms_for_replicator}
\begin{aligned}
b^{(K)}_i(\mathbf{x}) &= x_ib^{\textrm{(ind)}}_{i}(\mathbf{x}) + \mu Q_i(\mathbf{x})\\
d^{(K)}_i(\mathbf{x}) &= x_id^{\textrm{(ind)}}_i(\mathbf{x})
\end{aligned}
\end{equation}
where $b^{\textrm{(ind)}}_{i}(\mathbf{x})$ and $d^{\textrm{(ind)}}_{i}(\mathbf{x})$ are non-negative functions that respectively describe the per-capita birth and death rate of type $i$ individuals, $\mu \geq 0$ is a constant describing the mutation rate in the population, and $Q_i(\mathbf{x})$ is a non-negative function that describes the additional birth rate of type $i$ individuals due to mutations in the population $\mathbf{x}$ that cannot be captured in the per-capita birth rate\footnote{When $x_i = 0$, \emph{i.e.} there are no type $i$ individuals in the population, individuals of type $i$ may still be born through mutations during births of the other types. This cannot be captured in $b^{\textrm{(ind)}}_{i}(\mathbf{x})$ because the term $x_ib^{\textrm{(ind)}}_{i}(\mathbf{x})$ vanishes when $x_i = 0$. Note that no analogous problem exists for the death rate, since the death rate of type $i$ individuals must be 0 when $x_i$ is 0 to ensure that we never have negative population densities.}. Our assumptions of the functional forms \eqref{nD_functional_forms_for_replicator} thus amount to saying that birth and death rates can be separated into mutational and non-mutational components, and furthermore that the density dependence of the birth and death rates due to non-mutational effects is in a form that allows us to write down per-capita birth and death rates for each type. We define the \emph{Malthusian fitness} of the $i\textsuperscript{th}$ type as $w_i(\mathbf{x}) \coloneqq b^{\textrm{(ind)}}_{i}(\mathbf{x}) - d^{\textrm{(ind)}}_{i}(\mathbf{x})$, and the \emph{per-capita turnover rate} of the $i\textsuperscript{th}$ type as $\tau_i(\mathbf{x}) = b^{\textrm{(ind)}}_{i}(\mathbf{x}) + d^{\textrm{(ind)}}_{i}(\mathbf{x})$.  The quantity $w_i(\mathbf{x})$ describes the per-capita growth rate of type $i$ individuals in a population $\mathbf{x}$ discounting mutation. Ecologists often denote this quantity by the symbol $r_i$ and simply call it the (exponential) growth rate of type $i$, but we will stick to $w_i$ and `fitness' here. It is notable that both $w_i$ and $\tau_i$ depend on the state of the population as a whole (\textit{i.e.} $\mathbf{x}$) and not just on the density of the focal type. Thus, in general, both the fitness and the turnover rate in our model are frequency-dependent.

\section{Statistical measures for population-level quantities}\label{sec_stat_measures}
Given a state $\mathbf{x}(t)$ that describes our population at time $t$, we can compute the total (scaled) population size and the frequency of each type in the population as:
\begin{equation}
\label{nD_tot_pop_and_prop_inds_defn}
\begin{aligned}
N_{K}(t) &\coloneqq \sum\limits_{i=1}^{m}x_i(t) = \frac{1}{K}\sum\limits_{i=1}^{m}v_i(t)\\
p_i(t) &\coloneqq \frac{x_i(t)}{N_{K}(t)}
\end{aligned}
\end{equation}
These definitions are important because evolution is often measured as changes in type frequency (and \emph{not} necessarily changes in type density). Note that type frequency is a population level. Indeed, even though the causes of evolution are generally at the individual level, we are very often interested in quantities \emph{described} at a population level, such as the mean fitness or mean phenotype in the population~\citep{bourrat_evolution_2019}. Furthermore, the relevant quantities at the individual level, such as individual fitness or phenotype, are typically equal for all individuals of the same type (in some sense this is our basis for defining different types in the first place), and we, therefore, call them `type-level' quantities below. Let $f$ be any type-level quantity with (possibly time-dependent) value $f_i$ for the $i\textsuperscript{th}$ type. For example, if each type is a phenotype for a trait such as height, which can be assigned a numerical value, then setting $f_i = \textit{value of $i\textsuperscript{th}$ phenotype}$ gives us the mean trait value in the population. To facilitate the description of such quantities, we define the statistical mean value of any quantity $f$ in the population as
\begin{equation}
\label{nD_mean}
\overline{f}(t) \coloneqq \sum\limits_{i=1}^{m}f_ip_{i}
\end{equation}
the statistical covariance of two such quantities $f$ and $g$ as
\begin{equation}
\label{nD_cov}
\textrm{Cov}(f,g) \coloneqq \overline{fg} - \overline{f}\overline{g}
\end{equation}
and the statistical variance of a quantity $f$ as $\sigma^2_f \coloneqq \textrm{Cov}(f,f)$. It is important to recognize that these quantities are distinct from and independent of the \emph{probabilistic} expectation, variance, and covariance obtained by integrating over realizations in the underlying probability space. Indeed, for finite populations, the statistical mean, statistical variance, and statistical covariance are all themselves stochastic processes: For each instant of time, these population-level quantities are a random variable (\emph{i.e.} a \emph{function} and not just a number) depending on $\mathbf{p}$, the (random) vector of type frequencies in the population. For infinite populations, the statistical mean, variance, and covariance are entirely deterministic time-dependent quantities that simply describe how $f$ is distributed across the population. Failure to clearly make this distinction between statistical operations and probabilistic operations has led to much confusion with regard to the infinite population Price equation~\citep{van_veelen_use_2005}, which is entirely deterministic.

\section{Stochastic Trait Frequency Dynamics}\label{sec_nD_freq_eqns}

In appendix \ref{App_density_to_freq}, we show that we can use It\^{o}'s formula to write  down a general stochastic equation for the frequencies of each type in the population. Unlike~\citep{mcleod_social_2019}, we make no assumptions about the separation of ecological and evolutionary time scales or the strength of selection and are able to present an entirely general calculation.  Letting $\overline{w} = \sum w_ip_i$ and $\overline{\tau} = \sum \tau_i p_i$ be the average population fitness and turnover respectively, we show in appendix \ref{App_density_to_freq} that the frequency of the $i\textsuperscript{th}$ type in the population $\mathbf{x}(t)$ changes according to the equation:
\begin{equation}
\label{nD_eqn_for_frequencies}
\begin{aligned}
dp_i(t) &= \left[(w_i(\mathbf{x}) - \overline{w})p_i + \mu\left\{Q_i(\mathbf{p}) - p_i\left(\sum\limits_{j=1}^{m}Q_j(\mathbf{p})\right)\right\}\right]dt\\
&- \frac{1}{K}\frac{1}{N_{K}(t)}\left[(\tau_i(\mathbf{x}) - \overline{\tau})p_i + \mu\left\{Q_i(\mathbf{p}) - p_i\left(\sum\limits_{j=1}^{m}Q_j(\mathbf{p})\right)\right\}\right]dt\\
&+ \frac{1}{\sqrt{K}}\frac{1}{N_{K}(t)}\left[\left(A^{+}_{i}\right)^{1/2}dW^{(i)}_t - p_i\sum\limits_{j=1}^{m}\left(A^{+}_{j}\right)^{1/2}dW^{(j)}_t\right]
\end{aligned}
\end{equation}
where $W^{(1)}_t,W^{(2)}_t, \ldots, W^{(m)}_t$ are $m$ independent one-dimensional standard Brownian motion processes and we have used the notation $Q_i(\mathbf{p}) = Q_i(\mathbf{x})/N_K(t)$ for notational clarity. We will show below that the first term in this expression describes directional changes in the population composition due to `classical' evolutionary forces such as selection and mutation that occur in deterministic infinite population models. The second term is an additional directional force on population composition that is only seen in finite populations and can be thought of as a biasing `selection' for reduced turnover rate due to an effect similar to gambler's ruin in probability theory. The consequences of this term, as well as connections with previous studies, are discussed in detail in Chapter \ref{chap_unification}. Finally, the last term of equation \eqref{nD_eqn_for_frequencies} describes non-directional stochastic effects due to fluctuations and has a `spreading effect'.

\section{The infinite population limit}\label{sec_nD_det_limit}
Like in \ref{sec_1D_processes}, we can once again take $K \to \infty$ in \eqref{nD_Ito_SDE} to obtain a deterministic expression. Here, the expression reads
\begin{equation}
\label{nD_det_limit}
\frac{d\mathbf{x}}{dt} = \mathbf{A^-}(\mathbf{x}) = \mathbf{b}^{(K)}(\mathbf{x}) - \mathbf{d}^{(K)}(\mathbf{x})
\end{equation}
where the $m$-dimensional vector-valued functions $\mathbf{b}^{(K)}(\mathbf{x})$ and $\mathbf{d}^{(K)}(\mathbf{x})$ on the RHS are defined as having $i$\textsuperscript{th} element $b^{(K)}_i(\mathbf{x})$ and $d^{(K)}_i(\mathbf{x})$ respectively. For the trait frequencies, by taking $K \to \infty$ in \eqref{nD_eqn_for_frequencies}, we obtain a deterministic equation that reads:
\begin{equation}
\label{nD_replicator_mutator}
\setlength{\fboxsep}{2\fboxsep}\boxed{\frac{dp_i}{dt} = (w_i(\mathbf{x}) - \overline{w})p_i + \mu\left[Q_i(\mathbf{p}) - p_i\left(\sum\limits_{j=1}^{m}Q_j(\mathbf{p})\right)\right]}
\end{equation}
The first term of \eqref{nD_replicator_mutator} describes changes due to faithful (non-mutational) replication, and the second describes changes due to mutation. For this reason, equation \eqref{nD_replicator_mutator} is called the \emph{replicator-mutator equation} in the evolutionary game theory literature, where the individual `types' are interpreted to be pure strategies. If in addition, each $w_i(\mathbf{x})$ is linear in $\mathbf{x}$, meaning we can write $w_i(\mathbf{x}) = \sum_{j}a_{ij}x_j$ for some set of constants $a_{ij}$, then we get the replicator-mutator equation for matrix games, and the constants $a_{ij}$ form the `payoff matrix'. As is well-known, the replicator equation (without mutation) for matrix games with $m$ pure strategies is equivalent to the generalized Lotka-Volterra equations for a community with $m-1$ species~\citep{hofbauer_evolutionary_1998}, providing the connection to community ecology.  Equation \eqref{nD_replicator_mutator} is also equivalent to Eigen's \emph{quasispecies equation} from molecular evolution if each `type' is interpreted as a genetic sequence and each $w_i(\mathbf{x})$ is a constant function\footnote{Mutational effects are often additionally assumed to act through direct `transmission probabilities' of mutating from one type to another. This means that we can write $Q_i(\mathbf{p}) = \sum_j Q_{ij}p_j$, where $Q_{ii} = 0$, and for each $j \neq i$, $Q_{ij} \geq0$ is a constant describing the probability of a $j \to i$ mutation (conditioned on the occurrence of a mutation). Substituting this into \eqref{nD_replicator_mutator} yields an equation in terms of `$Q$-matrices' or `mutation matrices' that may be more familiar to some.}\citep{page_unifying_2002}. We can now calculate how the mean of any `type level' quantity $f$, defined as $f_i$ for the $i$\textsuperscript{th} type, changes in the population (For example, if each type is a phenotype for a trait such as height, which can be assigned a numerical value, then setting $f_i = \textit{value of $i\textsuperscript{th}$ phenotype}$ gives us the mean trait value in the population). The product rule of calculus tells us that we have the relation
\begin{equation}
\label{product_rule_for_nD_price}
\frac{d}{dt}\left(\sum\limits_{i=1}^{m}f_ip_i\right) = \sum\limits_{i=1}^{m}\left(f_i\frac{\partial p_i}{\partial t} + p_i\frac{\partial f_i}{\partial t}\right) = \sum\limits_{i=1}^{m}f_i\frac{\partial p_i}{\partial t} + \overline{\left(\frac{\partial f}{\partial t}\right)}
\end{equation}
Multiplying both sides of equation \eqref{nD_replicator_mutator} by $f_i$ and summing over all $i$, we obtain
\begin{align*}
\sum\limits_{i=1}^{m}f_i\frac{\partial p_i}{\partial t} &= \sum\limits_{i=1}^{m}f_iw_i(\mathbf{x})p_i - \overline{w}\sum\limits_{i=1}^{m}f_ip_i + \mu\left[\sum\limits_{i=1}^{m}Q_i(\mathbf{p})f_i - \left(\sum\limits_{j=1}^{m}Q_j(\mathbf{p})\sum\limits_{i=1}^{m}p_if_i\right)\right]\\
\Rightarrow \frac{d\overline{f}}{dt} &= \overline{wf}-(\overline{w})(\overline{f}) + \mu\left[\sum\limits_{i=1}^{m}Q_i(\mathbf{p})f_i - \left(\sum\limits_{j=1}^{m}Q_j(\mathbf{p})\right)\overline{f}\right]
\end{align*}
Using the definition of statistical covariance from \eqref{nD_cov}, we obtain
\begin{equation}
\sum\limits_{i=1}^{m}f_i\frac{\partial p_i}{\partial t} = \mathrm{Cov}(w,f) + \mu\left[\sum\limits_{i=1}^{m}Q_i(\mathbf{p})f_i - \left(\sum\limits_{j=1}^{m}Q_j(\mathbf{p})\right)\overline{f}\right] 
\end{equation}
Thus, substituting this into \eqref{product_rule_for_nD_price}, we get
\begin{equation}
\label{nD_Price_time_dependent}
\setlength{\fboxsep}{2\fboxsep}\boxed{\frac{d\overline{f}}{dt} = \mathrm{Cov}(w,f) + \mu\left[\sum\limits_{i=1}^{m}Q_i(\mathbf{p})f_i - \left(\sum\limits_{j=1}^{m}Q_j(\mathbf{p})\right)\overline{f}\right] + \overline{\left(\frac{\partial f}{\partial t}\right)}}
\end{equation}
This is a Price equation for quantities $f_i$ which can vary over time~\citep{lion_theoretical_2018}. To obtain the more familiar Price equation seen in textbooks, we can consider time-independent $f_i$, \emph{i.e.} situations in which each $f_i$ is constant over time, and thus changes in $\overline{f}$ are purely due to changes in the composition of the population. For such quantities, we have $\frac{\partial f_i}{\partial t} = 0 \ \forall \ i$ and thus obtain the dynamic version of the famous Price equation~\citep{page_unifying_2002,lion_theoretical_2018}:
\begin{equation}
\label{nD_Price}
\setlength{\fboxsep}{2\fboxsep}\boxed{
	\frac{d\overline{f}}{dt} = \mathrm{Cov}(w,f) + \mu\left[\sum\limits_{i=1}^{m}Q_i(\mathbf{p})f_i - \left(\sum\limits_{j=1}^{m}Q_j(\mathbf{p})\right)\overline{f}\right]}
\end{equation}
The first term of the RHS describes the statistical covariance between the quantity $f$ and the fitness $w$. The second term describes `transmission bias' due to mutational effects - The first summation is the `inflow' of $f$ due to mutations, and the second is the `outflow'.

\section{Stochastic fluctuations and the weak noise approximation}

As in the one-dimensional case, we can go a little further if the noise is sufficiently weak. Let the deterministic trajectory obtained by solving \eqref{nD_det_limit} be given by $\boldsymbol{\alpha}(t)$.  We can once again track 
stochastic fluctuations from the deterministic trajectory by introducing the new variables
\begin{equation}
\begin{aligned}
\mathbf{y} &= \sqrt{K}(\mathbf{x} - \boldsymbol{\alpha}(t))\\
s&=t\\
\tilde{P}(\mathbf{y},s) &= \frac{1}{\sqrt{K}}P(\mathbf{x},t)
\end{aligned}
\end{equation}
Then, after some algebra that follows the exact same steps as in section \ref{sec_1D_WNA} and retaining only the highest order terms in $\sqrt{K}$, we obtain the equation:
\begin{equation}
\label{nD_WNA_intermediate}
\frac{\partial \Tilde{P}_{0}}{\partial s}(\mathbf{y},s) = \sum\limits_{j=1}^{m}\left(-\frac{\partial}{\partial y_j}\left\{(A^{-}_{j})_{1}(s)\Tilde{P}_{0}(\mathbf{y},s)\right\}+\frac{1}{2}{A_j}^{+}(\boldsymbol{\alpha}(s))\frac{\partial^2}{\partial{y_j}^2}\{\Tilde{P}_{0}(\mathbf{y},s)\}\right)
\end{equation}
where $(A^{-}_{j})_{1}(s)$ is the $\mathcal{O}(1/\sqrt{K})$ term of the power series expansion
\begin{equation*}
A^-_{j}(\boldsymbol{\alpha} + \frac{\mathbf{y}}{\sqrt{K}}) = \sum\limits_{n=1}^{\infty}(A^{-}_{j})_{n}(s)\left(\frac{\mathbf{y}}{\sqrt{K}}\right)^n
\end{equation*}
In the case where the series expansion is a Taylor expansion, then the first-order term of this expansion is given by
\begin{equation}
\label{nD_WNA_taylor_term}
(A^{-}_{j})_{1}(s) = \sum\limits_{i=1}^{m} y_i\left(\frac{\partial A^{-}_j(\mathbf{x})}{\partial x_i}\bigg{|}_{\mathbf{x}=\boldsymbol{\alpha}(s)}\right)
\end{equation}
In multi-variable calculus, the directional derivative\footnote{Some authors use the notation $\partial_{\mathbf{v}}f(\mathbf{x})$ or $\mathbf{v}\cdot\nabla f(\mathbf{x})$ for this object.} $D_{\mathbf{v}}(f(\mathbf{x}))$ of a multidimensional function $f: \mathbb{R}^m \to \mathbb{R}$ along a vector $\mathbf{v}$ is the function defined by:
\begin{equation}
\label{directional_derivative_defn}
D_{\mathbf{v}}(f(\mathbf{x})) \coloneqq \sum\limits_{i=1}^{m}\left(\frac{\partial f(\mathbf{x})}{\partial x_i}\right)v_i = \lim_{h \to 0}\frac{f(\mathbf{x}+h\mathbf{v})-f(\mathbf{x})}{h}
\end{equation}
Comparing with \eqref{nD_WNA_taylor_term}, we see that the weak-noise approximation of our process is:
\begin{equation}
\label{nD_WNA}
\frac{\partial P}{\partial t}(\mathbf{y},t) = \sum\limits_{j=1}^{m}\left(-\frac{\partial}{\partial y_j}\left\{D_{\mathbf{y}}(A_j^-(\boldsymbol{\alpha}))(t)P(\mathbf{y},t)\right\}+\frac{1}{2}{A_j}^{+}(\boldsymbol{\alpha}(t))\frac{\partial^2}{\partial{y_j}^2}\{P(\mathbf{y},t)\}\right)
\end{equation}
where we have dropped the tildes and gone back from $s$ to $t$ for notational clarity. The directional derivative of the population turnover rate $A_j^-$ `in the direction' of the stochastic fluctuation $\mathbf{y}$ at the deterministic point $\boldsymbol{\alpha}(s)$ here is the multidimensional analogue of the derivative we had in \eqref{1D_WNA}. The meaning of equation \eqref{nD_WNA} is clearer if we compute how the moments of the fluctuation $y_i$ in the density of type $i$ individuals (for some $i$) change over time. Let $n > 0$. We have:
\begin{align}
\frac{d}{dt}\mathbb{E}[y_i^n] &= \frac{d}{dt}\int\limits_{\mathbb{R}^m}y_i^nP(\mathbf{y},t)d\mathbf{y}\\
&= \int\limits_{\mathbb{R}^m}y_i^n\frac{\partial P}{\partial t}(\mathbf{y},t)d\mathbf{y}\label{nD_change_of_moments_defn}
\end{align}
where we have assumed that $y_i^n$ and $P(\mathbf{y},t)$ vary sufficiently smoothly to allow us to interchange the order of derivatives and integrals and used the shorthand $\displaystyle \int\limits_{\mathbb{R}^m} \ f(\mathbf{y}) \ d\mathbf{y} = \int\limits_{\mathbb{R}}\int\limits_{\mathbb{R}}\cdots\int\limits_{\mathbb{R}} \ f(\mathbf{y}) \ dy_1 dy_2 \ldots dy_m$. The one-dimensional integrals are over the entire real line and not just over $[0,\infty)$ because fluctuations can be either positive (greater than $\boldsymbol{\alpha}(t)$) or negative (lesser than $\boldsymbol{\alpha}(t)$). For notational brevity, let us use the shorthand $D_j = D_{\mathbf{y}}(A_j^-(\boldsymbol{\alpha}))(t)$. We can now substitute \eqref{nD_WNA} into \eqref{nD_change_of_moments_defn} to obtain
\begin{align}
\frac{d}{dt}\mathbb{E}[y_i^n] &= \int\limits_{\mathbb{R}^m} y_i^n \left(\sum\limits_{j=1}^{m}\left(-\frac{\partial}{\partial y_j}\left\{D_{j}P(\mathbf{y},t)\right\}+\frac{1}{2}{A_j}^{+}(\boldsymbol{\alpha}(t))\frac{\partial^2}{\partial{y_j}^2}\{P(\mathbf{y},t)\}\right)\right)d\mathbf{y}\\
&= \sum\limits_{j=1}^{m}\left[-\int\limits_{\mathbb{R}^m} y_i^n\frac{\partial}{\partial y_j}\left\{D_{j}P(\mathbf{y},t)\right\}d\mathbf{y} + \frac{{A_j}^{+}(\boldsymbol{\alpha}(t))}{2}\int\limits_{\mathbb{R}^m} y_i^n\frac{\partial^2}{\partial{y_j}^2}\{P(\mathbf{y},t)\}d\mathbf{y}\right]\label{nD_intermediate_for_moments}
\end{align}
We will evaluate the integrals on the RHS of \eqref{nD_intermediate_for_moments} using integration by parts. Recall that for any two functions $u$ and $v$ defined on a domain $\Omega$, the general formula for integration by parts is given by:
\begin{equation}
\label{int_by_parts_general_formula}
\int\limits_{\Omega}\frac{\partial u}{\partial x_i}vd\mathbf{x} = -\int\limits_{\Omega}u\frac{\partial v}{\partial x_i}d\mathbf{x} + \int\limits_{\partial\Omega}uv\gamma_{i}dS(\mathbf{x})
\end{equation}
where $\partial \Omega$ is the boundary of $\Omega$, $dS$ is the surface element of this boundary, and $\gamma_i$ is the $i\textsuperscript{th}$ component of the unit outward normal to the boundary. In our case, we have $\Omega = \mathbb{R}^m$, and thus the boundary conditions are evaluated as $\|y\| \to \infty$. We assume that the magnitude of stochastic fluctuations is bounded, and therefore impose the condition $\displaystyle \lim_{\|y\| \to \infty}  P(\mathbf{y},t) = 0$. Further, we assume that this decay is fast enough that $\displaystyle \lim_{\|y\| \to \infty}D_jP(\mathbf{y},t) = 0\ \forall \ j$. Under these conditions, we can evaluate the two integrals in the RHS of \eqref{nD_intermediate_for_moments} by using integration by parts and discarding the boundary term (The second term on the RHS of \eqref{int_by_parts_general_formula}). Note that since the $y_i$s are orthogonal to each other, we have the relation:
\begin{equation*}
\frac{\partial y_i ^{n}}{\partial y_j} = \delta_{ij}ny_i^{n-1}
\end{equation*}
Using this relation and then using integration by parts on the RHS of \eqref{nD_intermediate_for_moments} (once for the first term and twice for the second term), we obtain the considerably simpler expression
\begin{align}
\frac{d}{dt}\mathbb{E}[y_i^n] &= n\int\limits_{\mathbb{R}^m} y_i^{n-1}D_{i}P(\mathbf{y},t)d\mathbf{y} + \frac{n(n-1)}{2}A_i^+(\boldsymbol{\alpha}(t))\int\limits_{\mathbb{R}^m} y_i^{n-2}P(\mathbf{y},t)d\mathbf{y}\\
\Rightarrow \frac{d}{dt}\mathbb{E}[y_i^n] &= n\mathbb{E}[y_i^{n-1}D_{i}]+\frac{n(n-1)}{2}A_i^+(\boldsymbol{\alpha}(t))\mathbb{E}[y_i^{n-2}]\label{nD_general_moment_eqns}
\end{align}
Of particular interest are the cases $n=1$ (corresponding to the expected value of $y_i$) and $n=2$ (which can be used along with the expected value to compute the variance of $y_i$). We have:
\begin{align}
\frac{d}{dt}\mathbb{E}[y_i] &= \mathbb{E}[D_{i}]\label{nD_moment_eqn_mean}\\
\frac{d}{dt}\mathbb{E}[y_i^2] &= 2\mathbb{E}[y_iD_{i}] +  A_i^+(\boldsymbol{\alpha}(t)) = 2\mathrm{Cov}(y_i,D_i) + 2\mathbb{E}[y_i]\mathbb{E}[D_i]+A_i^+(\boldsymbol{\alpha}(t))\label{nD_moment_eqn_2nd_mom}
% \Rightarrow \frac{d}{dt}\mathrm{Var}(y_i) &= - \mathbb{E}[D_{i}]^2 + 2\mathbb{E}[y_iD_{i}] +  A_i^+(\boldsymbol{\alpha}(t))\label{nD_moment_eqn_var}
\end{align}
Thus, whether stochastic fluctuations are expected to grow or decay is controlled by $D_i$, a measure of how the growth rate ($b_i - d_i$) changes along the direction of the fluctuation, whereas the spread of the fluctuations (the variance) has contributions from the net turnover rate ($A_i^+ = b_i + d_i$) and the covariance between the fluctuation and $D_i$. Note that unlike in the Price equation \eqref{nD_Price}, this is a true \emph{probability} covariance (as opposed to a statistical covariance between two deterministic quantities). In the case of the functional forms given by \eqref{nD_functional_forms_for_replicator}, we have:
\begin{equation}
A_i^-(\mathbf{x}) = w_i(\mathbf{x})x_i + \mu Q_i(\mathbf{x})
\end{equation}
and thus, from \eqref{nD_WNA_taylor_term}, we can calculate the directional derivative $D_i$ as
\begin{align}
D_i &= \sum\limits_{k=1}^{m} y_k\left(\frac{\partial A^{-}_i(\mathbf{x})}{\partial x_k}\bigg{|}_{\mathbf{x}=\boldsymbol{\alpha}(t)}\right)\\
&= \sum\limits_{k=1}^{m} y_k\left(\frac{\partial}{\partial x_k}\left( w_i(\mathbf{x})x_i + \mu Q_i(\mathbf{x})\right)\bigg{|}_{\mathbf{x}=\boldsymbol{\alpha}(t)}\right)\\
&= \sum\limits_{k=1}^{m} y_k\left(a_i\frac{\partial w_i}{\partial x_k}\bigg{|}_{\mathbf{x}=\boldsymbol{\alpha}(t)}\right) + y_iw_i(\boldsymbol{\alpha}) + \mu\sum\limits_{k=1}^{m} y_k\left(\frac{\partial Q_i}{\partial x_k}(\mathbf{x})\bigg{|}_{\mathbf{x}=\boldsymbol{\alpha}(t)}\right)\\
&= y_iw_i(\boldsymbol{\alpha}) + a_iD_{\mathbf{y}}(w_i(\boldsymbol{\alpha})) + \mu D_{\mathbf{y}}(Q_i(\boldsymbol{\alpha}))\label{nD_WNA_directional_derivative_for_replicator_eqns}
\end{align}
Using this in \eqref{nD_moment_eqn_mean}, we see that the expected change of a fluctuation in the density of type $i$ individuals evolves as:
\begin{equation}
\label{nD_moment_eqn_mean_replicator}
\frac{d}{dt}\mathbb{E}[y_i] = \underbrace{w_i(\boldsymbol{\alpha})\mathbb{E}[y_i]}_{\substack{\text{Current fitness of type $i$} \\ \text{at deterministic trajectory $\boldsymbol{\alpha}$} \\ \text{(scaled by expected density $\mathbb{E}[y_i]$)}}} + \underbrace{a_i\mathbb{E}[D_{\mathbf{y}}(w_i(\boldsymbol{\alpha}))]}_{\substack{\text{Expected change in fitness} \\ \text{ of type $i$ in going from $\boldsymbol{\alpha}$ to $\mathbf{y}$} \\ \text{(scaled by deterministic density $a_i$)}}} + \underbrace{\mu\mathbb{E}[D_{\mathbf{y}}(Q_i(\boldsymbol{\alpha}))]}_{\substack{\text{Expected effect of} \\ \text{mutations}}}
\end{equation}

