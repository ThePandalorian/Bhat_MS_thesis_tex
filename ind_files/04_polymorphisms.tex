\epigraph{\justifying Our future advances will not be concerned with universal laws, but instead with universal approaches to tackling particular problems}{Peter Kareiva}

In the previous chapter, we used various tools and arguments to illustrate how to obtain approximate equations for very general stochastic birth-death processes. In this chapter, we put this theory into use through examples to study extinction and diversity in finite populations.

\section{Example in one dimension: The stochastic logistic equation}
Consider the functional forms of example \ref{ex_1D_stoch_logistic}, given by
\begin{equation}
\label{ex_1D_stoch_logistic_BD_eqns}
\begin{aligned}
    b(n) &= \lambda n\\
    d(n) &= \left(\mu + (\lambda-\mu)\frac{n}{K}\right)n
\end{aligned}
\end{equation}
Here, $K$ is the system-size parameter. Introducing the new variable $x=n/K$, we obtain
\begin{align*}
    b_K(x) &= \frac{1}{K}b(n) = \frac{1}{K}\lambda Kx\\
    d_K(x) &= \frac{1}{K}d(n) = \frac{1}{K}\left(\mu + (\lambda-\mu)\frac{Kx}{K}\right)Kx
\end{align*}
Thus, we have
\begin{equation*}
    A^{\pm}(x) = b_K(x)\pm d_K(x) = x\left(\lambda \pm \left(\left(\mu + (\lambda-\mu)x\right)\right) \right)
\end{equation*}
Defining $r=\lambda-\mu$ and $v=\lambda+\mu$ and using equation \eqref{1D_SDE}, we 
see that the `mesoscopic view' of the system is given by the solution of the SDE
\begin{equation}\label{ex_1D_stoch_logistic_full_SDE}
dX_t =  rX_t(1-X_t)dt + \sqrt{\frac{X_t(v+rX_t)}{K}}dB_t
\end{equation}
From equation \eqref{1D_det_limit}, we see that the deterministic dynamics are
\begin{equation}\label{ex_1D_stoch_logistic_det_limit}
\frac{dx}{dt} = A^-(x) = rx(1-x)
\end{equation}
showing that in the infinite population limit, we
obtain the logistic equation. Letting $\alpha(t)$ be the solution of the logistic equation \eqref{ex_1D_stoch_logistic_det_limit}, We can Taylor expand $A^{\pm}(x)$ for the weak noise approximation, and we find:
\begin{align*}
A^-_1(x) &= \frac{d}{dx}(rx(1-x))\biggl{|}_{x=\alpha} = r(1 - 2\alpha(t))\\
A^+_0(x) &= \alpha(t)(v+r\alpha(t))
\end{align*}
Thus, the weak noise approximation of \ref{ex_1D_stoch_logistic_BD_eqns} is given by
\begin{equation}
    X_t = \alpha(t) + \frac{1}{\sqrt{K}}Y_t
\end{equation}
where the stochastic process $Y_t$ is an Ornstein-Uhlenbeck process given by the solution to the linear SDE
\begin{align}
    dY_t &= A^-_1(t)Y_tdt + \sqrt{A^+_0(t)}dB_t\nonumber\\
    \Rightarrow dY_t &= r(1 - 2\alpha(t))Y_tdt + \sqrt{\alpha(t)(v+r\alpha(t))}dB_t\label{ex_1D_stoch_logistic_WNA}
\end{align}

The time series predicted by these three processes look qualitatively similar and all seem to fluctuate about the deterministic steady state (Figure \ref{fig_1D_stoch_logistic_timeseries}).

\myfig{1}{Media/4.1_stoch_logistic_timeseries.png}{Comparison of a single realization of the exact birth-death process \eqref{ex_1D_stoch_logistic_BD_eqns}, the deterministic trajectory \eqref{ex_1D_stoch_logistic_det_limit}, the non-linear Fokker-Planck equation \eqref{ex_1D_stoch_logistic_full_SDE}, and the weak noise approximation \eqref{ex_1D_stoch_logistic_WNA} for \textbf{(A)} $K = 500$, \textbf{(B)} $K = 1000$, and \textbf{(C)} $K = 10000$. $\lambda = 2, \mu = 1$ for all thee cases.}{fig_1D_stoch_logistic_timeseries}

The deterministic trajectory \eqref{ex_1D_stoch_logistic_det_limit} has two fixed points, one at $x=0$ (extinction) and one at $x=1$ (corresponding to a population size of $n=K$). For $r > 0$, $x=0$ is unstable and $x=1$ is a global attractor, meaning in the deterministic limit, when $r > 0$, all populations end up at $x=1$ given enough time. The stochastic dynamics \eqref{ex_1D_stoch_logistic_full_SDE} and \eqref{ex_1D_stoch_logistic_WNA} depend not only on $r$, but also on $v$, the sum of the birth and death rates. It has been proven that $X_t = 0$ is the only recurrent state for the full stochastic dynamics \eqref{ex_1D_stoch_logistic_full_SDE}, meaning that every population is guaranteed to go extinct\footnote{This can be proven using tools from Markov chain theory. For those interested, the proof uses ergodicity to arrive at a contradiction if any state other than $0$ exhibits a non-zero density at steady state.} given enough time \citep{nasell_extinction_2001}, thus illustrating an important difference between finite and infinite populations. $X_t = 0$ is also an `absorbing' state since once a population goes extinct, it has no way of being revived in this model. However, if $K$ is large enough, the eventual extinction of the population may take a very long time. In fact, we can make the expected time to extinction arbitrarily long by making $K$ sufficiently large. Thus, for moderately large values of $K$, it is biologically meaningful only to look at a weaker version of the steady state distribution by imposing the condition that the population does not go extinct and looking at the `transient' dynamics \citep{hastings_transients_2004}. Conditioned on non-extinction, the solution to \eqref{ex_1D_stoch_logistic_full_SDE} has a `quasistationary' distribution about the deterministic attractor $X_t = 1$, with some variance reflecting the effect of noise-induced fluctuations in population size \citep{nasell_extinction_2001} due to the finite size of the population. The weak-noise approximation \eqref{ex_1D_stoch_logistic_WNA} implicitly assumes non-extinction by only measuring small fluctuations from the deterministic solution to \eqref{ex_1D_stoch_logistic_det_limit} and thus, at steady state, naturally describes a quasistationary distribution centered about $X_t = 1$. The steady-state density (probability density function as $t \to \infty$) of the exact birth-death process \eqref{ex_1D_stoch_logistic_BD_eqns} is compared with that predicted by \eqref{ex_1D_stoch_logistic_full_SDE} and \eqref{ex_1D_stoch_logistic_WNA} for various values of $K$ in figure \ref{fig_1D_stoch_logistic_densities}.

\myfig{0.85}{Media/4.2_stoch_logistic_distributions.png}{Comparison of the steady-state densities given by \eqref{ex_1D_stoch_logistic_BD_eqns}, \eqref{ex_1D_stoch_logistic_full_SDE}, and \eqref{ex_1D_stoch_logistic_WNA} for \textbf{(A)} $K = 500$, \textbf{(B)} $K = 1000$, and \textbf{(C)} $K = 10000$. $\lambda = 2, \mu = 1$ for all thee cases. Each curve was obtained using $1000$ independent realizations.}{fig_1D_stoch_logistic_densities}

\section{Example for discrete traits: Lotka-Volterra and matrix games in finite populations}

The methods outlined in the above section have recently been used to study the population dynamics of a finite population playing a so-called `matrix game' (An evolutionary game for which you can write down a payoff matrix) with 2 pure strategies \citep{tao_stochastic_2007}. Based on the interpretation of what each type represents, this is mathematically equivalent to studying frequency-dependent selection on a one-locus two-allele gene (with a bijective genotype-phenotype map and no mutations) or studying two-species competitive Lotka-Volterra dynamics, as we will show below. The stochastic Lotka-Volterra competition model shown below has also been proved to be equivalent to an $m$-allele Moran model under certain limits \citep{constable_mapping_2017}.\\
\\
Let us imagine a population with $m$ types of individuals that are competing for resources. Let the state of the population be characterized by the vector $\mathbf{v}(t) = [v_1(t),v_2(t),\ldots,v_m(t)]$, where $v_i(t)$ is the number of type $i$ individuals at time $t$. Let the birth and death rates of the $i$th type be given by:
\begin{equation}
\label{nD_example_numbers_b_d_rates}
\begin{aligned}
b_i(\mathbf{v}) &= \lambda v_i\\
d_i(\mathbf{v}) &= \left(\mu + \frac{1}{K}\left(\sum\limits_{j=1}^{m}M_{ij}v_j\right)\right)v_i
\end{aligned}
\end{equation}
where $K > 0$ is our system size parameter (and represents a global carrying capacity across all types), $\lambda > 0$ and $\mu > 0$ are suitable positive constants representing the baseline natality and mortality common to all types, and $M_{ij} \geq 0$ is a non-negative constant describing the effect of type $j$ individuals on the death rate of type $i$ individuals due to competition. We assume that $M_{ij} \ll K$. The values $M_{ij}$ are often collected in an $m \times m$ matrix $\mathbf{M}$. The negative of this matrix, $-\mathbf{M}$, is called the `payoff matrix' (in evolutionary game theory) or `interaction matrix' (in Lotka-Volterra models), which is why the infinite population analogues of such models are called `matrix games' in the evolutionary game theory literature. Lotka-Volterra models also frequently assume that the diagonal elements $M_{ii}$ are all equal, though we will not make that assumption here.\\
\\
Going from population numbers $\mathbf{v}$ to densities $\mathbf{x} = \mathbf{v}/K$, we obtain the birth and death rates:
\begin{equation}
\label{nD_example_density_b_d_rates}
\begin{aligned}
b^{(K)}_i(\mathbf{x}) &= \lambda x_i\\
d^{(K)}_i(\mathbf{x}) &= \left(\mu + \sum\limits_{j=1}^{m}M_{ij}x_j\right)x_i
\end{aligned}
\end{equation}
Thus, we have
\begin{equation*}
A^{\pm}_{i} = x_i\left(\lambda \pm \left(\mu + \sum\limits_{j=1}^{m}M_{ij}x_j\right)\right)
\end{equation*}
Defining $r = \lambda - \mu$ and $v = \lambda + \mu$, we see from equation \eqref{nD_Ito_SDE} that the mesoscopic view is the $m$ dimensional SDE given by
\begin{equation}
\label{nD_example_SDE}
d\mathbf{X}_{t} = \mathbf{A^-}(\mathbf{X}_t)dt + \frac{1}{\sqrt{K}}\mathbf{D}(\mathbf{X}_t)d\mathbf{B}_t
\end{equation}
where 
\begin{equation*}
\mathbf{A^-}_i = {(\mathbf{X}_{t})}_i(r - \sum\limits_{j=1}^{m}M_{ij}{(\mathbf{X}_{t})}_j) 
\end{equation*}
and
\begin{equation*}
(\mathbf{D}\mathbf{D}^{\mathrm{T}})_i = {(\mathbf{X}_{t})}_i(v + \sum\limits_{j=1}^{m}M_{ij}{(\mathbf{X}_{t})}_j) 
\end{equation*}
From \eqref{nD_det_limit}, we see that the deterministic limit is a set of $m$ coupled ODEs given by
\begin{equation}
\label{nD_example_det_limit}
\frac{d x_i}{dt} = x_i\left(r - \sum\limits_{j=1}^{m}M_{ij}x_j\right)
\end{equation}
These are precisely the competitive Lotka-Volterra equations for a system of $m$ species. By matching the terms of \eqref{nD_example_density_b_d_rates} with those of \eqref{nD_functional_forms_for_replicator}, we can identify that we have $\mu = 0$ and
\begin{equation}
\label{nD_example_fitness}
\begin{aligned}
b^{(\textrm{int})}_{i}(\mathbf{x}) &= \lambda\\
d^{(\textrm{int})}_i(\mathbf{x}) &= \mu + \sum\limits_{j=1}^{m}M_{ij}x_j\\
w_i(\mathbf{x}) &= r - \sum\limits_{j=1}^{m}M_{ij}x_j
\end{aligned}
\end{equation}
If $p_i(t)$ is the frequency of type $i$ individuals in the population at time $t$ and $N_K(t) = \sum_i x_i(t)$, then the mean fitness is given by
\begin{align}
\overline{w}(t) &= \sum\limits_{i=1}^{m}w_ip_i\\
&= \sum\limits_{i=1}^{m}\left(r - \sum\limits_{j=1}^{m}M_{ij}x_j\right)p_i\\
&= r - \sum\limits_{i=1}^{m}p_i\left(\sum\limits_{j=1}^{m}M_{ij}x_j\right)
\end{align}
where we have used the fact that $\sum_i p_i = 1$ in the last line. Using \eqref{nD_replicator_mutator} to write down the equations for the frequencies $p_i$, we obtain
\begin{equation}
\frac{dp_i}{dt} = \left[\sum\limits_{i=1}^{m}p_i\left(\sum\limits_{j=1}^{m}M_{ij}x_j\right) - \sum\limits_{j=1}^{m}M_{ij}x_j\right]p_i
\end{equation}
Let us define the payoff matrix $\mathbf{B} = - \mathbf{M}$. Then, the dynamics are
\begin{equation}
\frac{1}{N_K(t)}\frac{dp_i}{dt} = \left[(\mathbf{Bp})_i - \mathbf{p}\cdot\mathbf{Bp}\right]p_i   
\end{equation}
which is the familiar version of the replicator equation seen in most textbooks, with an extra $N_K(t)$ factor to account for the fact that $\sum_i x_i$ is allowed to fluctuate in our model. If instead $N_K$ was a constant for all time, it could simply be absorbed into the definition of the payoff matrix $B$ to obtain exactly the replicator equation as presented in most ecology/evolution textbooks. We briefly note here that if $m$ is large, then both the stochastic dynamics \eqref{nD_example_SDE} and the deterministic limit \eqref{nD_example_det_limit} can be simplified from an $m$ dimensional system to an $m-1$ dimensional system by a coordinate transformation. If we go from the variables $x_1,\ldots,x_m$ to the variables $p_1,\ldots,p_{m-1},N_K$, then, we can exploit the fact that $N_K$ varies much less than the $p_i$ terms to project the system onto a `slow manifold' in which $N_K$ is approximately constant, thus obtaining an $m-1$ dimensional system of equations and recovering the relation between the Lotka-Volterra equations for $m$ species and the replicator equation for $m-1$ tactics \citep{constable_mapping_2017,parsons_dimension_2017}. However, we will not explore this further in this manuscript, and refer the reader to \citep{constable_stochastic_2013} and \citep{parsons_dimension_2017} for a review of the ideas of (stochastic) dynamics on slow manifolds.\\
Let the solution to the equations \eqref{nD_example_det_limit} be given by $\mathbf{a}(t) = [a_1(t),\ldots,a_m(t)]$. For the weak noise approximation, we can Taylor expand $A^{\pm}_i$ and use \eqref{nD_WNA_directional_derivative_for_replicator_eqns} to compute the directional derivative as:
\begin{align}
D_i &= y_iw_i(\mathbf{a}) + a_i\sum\limits_{k=1}^{m}y_k\left(\frac{\partial w_i}{\partial x_k}\bigg{|}_{\mathbf{x}=\mathbf{a}(t)}\right)\\
&= y_iw_i(\mathbf{a}) + a_i\sum\limits_{k=1}^{m}y_k\left(\frac{\partial}{\partial x_k}(r+\sum\limits_{j=1}^{m}B_{ij}x_j)\bigg{|}_{\mathbf{x}=\mathbf{a}(t)}\right)\\
&= y_iw_i(\mathbf{a}) + a_i\sum\limits_{k=1}^{m}y_kB_{ik}\\
\Rightarrow D_i &= y_iw_i(\mathbf{a}) + a_iw_i(\mathbf{y}) - ra_i\label{nD_example_directional_derivative}
\end{align}
where we have used the fact that $w_i(\mathbf{y}) = r + \sum\limits_{k=1}^{m}y_kB_{ik}$ (from \eqref{nD_example_fitness}) in the last step. Thus, in the weak noise approximation of our process, the dynamics are given by
\begin{equation}
\mathbf{x}(t) = \mathbf{a}(t) + \frac{1}{\sqrt{K}}\mathbf{y}(t)
\end{equation}
where the stochastic fluctuations $\mathbf{y}(t)$ satisfy the linear Fokker-Planck equation
\begin{equation}
\resizebox{1.1\textwidth}{!}{$\displaystyle\frac{\partial P}{\partial t}(\mathbf{y},t) = \sum\limits_{i=1}^{m}\left(-\frac{\partial}{\partial y_i}\left\{\left(y_iw_i(\mathbf{a}) + a_iw_i(\mathbf{y}) - ra_i\right)P(\mathbf{y},t)\right\}+\frac{1}{2}\left(a_i\left(v - \sum\limits_{j=1}^{m}B_{ij}a_j\right)\right)\frac{\partial^2}{\partial{y_i}^2}P(\mathbf{y},t)\right)$}
\end{equation}
Using \eqref{nD_example_directional_derivative} in \eqref{nD_moment_eqn_mean}, we see that the fluctuations are expected to evolve as:
\begin{equation}
\label{nD_example_moment_eqn_mean}
\frac{d}{dt}\mathbb{E}[y_i] = w_i(\mathbf{a})\mathbb{E}[y_i] + a_i\sum\limits_{k=1}^{m}B_{ik}\mathbb{E}[y_k]
\end{equation}
or, in matrix form:
\begin{equation}
\resizebox{0.93\textwidth}{!}{$\displaystyle
	\frac{d}{dt}\begin{bmatrix}
	\mathbb{E}[y_1]\\
	\mathbb{E}[y_2]\\
	\vdots\\
	\mathbb{E}[y_i]\\
	\vdots\\
	\mathbb{E}[y_m]
	\end{bmatrix}
	=
	\begin{bmatrix}
	(r + \sum\limits_{j=1}^{m}B_{1j}a_j + a_1B_{11}) & a_1B_{12} & a_1B_{13} & \dots & \dots & \dots & a_1B_{1m}\\
	a_2B_{21} & (r + \sum\limits_{j=1}^{m}B_{2j}a_j + a_2B_{22}) & a_2B_{23} & \dots & \dots & \dots & a_2B_{2m}\\
	\vdots &  & \ddots & &  & & \vdots\\
	a_{i}B_{i1} & a_iB_{i2} & a_iB_{i3} & \dots & (r + \sum\limits_{j=1}^{m}B_{ij}a_j + a_iB_{ii}) & \dots & a_iB_{im}\\
	\vdots &  &  & & & \ddots & \vdots\\
	a_mB_{m1} & a_mB_{m2} & a_mB_{m3} & \dots & \dots & \dots & (r + \sum\limits_{j=1}^{m}B_{mj}a_j + a_mB_{mm})
	\end{bmatrix}
	\begin{bmatrix}
	\mathbb{E}[y_1]\\
	\mathbb{E}[y_2]\\
	\vdots\\
	\mathbb{E}[y_i]\\
	\vdots\\
	\mathbb{E}[y_m]
	\end{bmatrix}
	$}
\end{equation}
The eigenvalues of the first matrix on the RHS will tell us whether the fixed point $\mathbb{E}[y_i] = 0 \ \forall \ i$ (the only fixed point of this system) is stable, or whether fluctuations are expected to grow (up to the point where the fluctuations are so large that the WNA is no longer valid).
\hl{can compare time series or something here if we think it is helpful. Visualization may be little hard though, because we always have $\geq 3$ dimensions ($m$, + 1 additional for time)}

\section{Example for quantitative traits}

\subsection{Interlude: Detecting clusters through Fourier analysis}

In section \ref{sec_infD_processes}, we used various approximations to arrive at the linear functional Fokker-Planck equation
\begin{equation}
\label{functional_WNE_chap_4}
    \frac{\partial P}{\partial t}(\zeta,t) = \int\limits_{\mathcal{T}}\left(-\frac{\delta}{\delta \zeta(x)}\left\{\mathcal{D}_{\zeta}[\mathcal{A}^{-}](x)P(\zeta,t)\right\}+\frac{1}{2}\mathcal{A}^{+}(x|\psi)\frac{\delta^2}{\delta\zeta(x)^2}\{P(\zeta,t)\}\right)dx
\end{equation}
for describing stochastic fluctuations $\zeta$ from the deterministic solution obtained by solving \eqref{deterministic_traj}. Our goal is now to find a method to effectively detect and describe evolutionary branches (modes in trait space, corresponding to individual morphs) for this process. We will do this by measuring the autocorrelation of the distribution of the population over trait space. A convenient theorem due to Weiner and Khinchin relates the autocorrelation of a probability distribution to its power spectral density via Fourier transformation. This has been extensively used in spatial ecology, and we too will make use of it here. Specifically, we will carry out a basis expansion of our functions in the Fourier basis $\{e^{ikx}\}_{k\in\mathbb{Z}}$. If $\mathcal{D}_{\zeta}[\mathcal{A}^{-}]$ is a translation-invariant\footnote{This is horrible nomenclature by the mathematicians. Though `invariant' is the conventional name for this concept, the intended meaning is not really invariant but `equivariant'. Formally, let $\mathcal{F}$ be a suitable function space of real valued functions. For any $c \in \mathbb{R}$, let $T_c: \mathcal{F} \to \mathcal{F}$ be the translation operator on this space, defined by $T_c[f(x)] = f(x+c)$. An operator $L: \mathcal{F} \to \mathcal{F}$ is said to be translation-invariant if it commutes with $T_c$ for every $c \in \mathbb{R}$, \emph{i.e.} $T_c[L[f]] = L[T_c[f]] \ \forall \ f \in \mathcal{F} \ \forall \ c \in \mathbb{R}$} linear operator, then $\exp(ikx)$ acts as an eigenfunction, significantly simplifying the calculations. We therefore assume this below.



%\includestandalone[width=.8\textwidth]{backend/fourier_figure}
\myfig{0.8}{Media/4.3_fourier_fig.png}{\textbf{Schematic description of Fourier analysis}. A function $\phi(x)$ (shown in red) over the trait space can be decomposed as the sum of infinitely many Fourier modes (shown in blue) $\phi_k$. In the Fourier dual space, we can look at the peaks of each of these Fourier modes: The magnitude of $\phi_k$ tells us how much it contributes to the actual function of interest $\phi$.}{fig_Fourier}

Assume that $\mathcal{D}_{\zeta}[\mathcal{A}^{-}]$ takes the form:
\begin{equation*}
 \mathcal{D}_{\zeta}[\mathcal{A}^-](x,t) = L[\zeta(x,t)]   
\end{equation*}
for a translation-invariant linear operator $L$ that only depends on $x$ and $t$. The presence of phenotypic clustering and polymorphisms can be analyzed by examining the power spectrum of $\Tilde{P}_{0}(\zeta,s)$ over the trait space.\\
We assume that $\zeta$, and $\mathcal{A}^{+}(x|\psi)$ admit the Fourier basis representations:
\begin{equation}
\label{fourier_representations_functions}
\begin{aligned}
\zeta(x,t) &= \sum\limits_{k=-\infty}^{\infty}e^{ikx}\zeta_k(t) \ \ ; \ \ \zeta_k(t) = \int\limits_{\mathcal{T}}\zeta(x,t)e^{-ikx}dx\\
\mathcal{A}^{+}(x|\psi) &= \sum\limits_{k=-\infty}^{\infty}e^{ikx}A_k(t) \ \ ; \ \ A_k(t) = \int\limits_{\mathcal{T}}\mathcal{A}^{+}(x|\psi)e^{-ikx}dx
\end{aligned}
\end{equation}
In this case, the functional derivative operator obeys:
\begin{equation}
\label{fourier_representations_derivative}
    \frac{\delta}{\delta \zeta(x)} = \sum\limits_{k=-\infty}^{\infty}e^{-ikx}\frac{\partial}{\partial \zeta_k}
\end{equation}
and since $L$ is linear and translation-invariant, we also have the relation\footnote{This is because $\exp(ikx)$ acts as an eigenfunction for translation invariant linear operators, and therefore, for any function $\varphi = \sum\varphi_k\exp(ikx)$, we have the relation $L[\varphi] = L[\sum\varphi_k\exp(ikx)]=\sum\varphi_kL[\exp(ikx)]=\sum\varphi_kL_k\exp(ikx)$, where $L_k$ is the eigenvalue of $L$ associated with the eigenfunction $\exp(ikx)$. It is helpful to draw the analogy with eigenvectors of matrices and view $L_k\varphi_k$ as the projection of $L[\varphi]$ along the $k$th eigenvector $e_k = \exp(ikx)$.}:
\begin{equation}
\label{fourier_representation_linear_operator}
    L[\zeta] = \sum\limits_{k=-\infty}^{\infty}L_{k}\zeta_ke^{ikx}
\end{equation}
where 
\begin{equation*}
    L_k = e^{-ikx}L[e^{ikx}]
\end{equation*}
Lastly, by definition of Fourier modes, we have, for any differentiable real function $F$ and any fixed time $t > 0$:
\begin{equation}
\label{fourier_mode_relation}
\frac{\partial}{\partial \zeta_j(t)}F(\zeta_i(t)) = \delta_{ij}F'(\zeta_j(t))
\end{equation}
where $\delta_{ij}$ is the Kronecker delta symbol.
Using \eqref{fourier_representations_functions}, \eqref{fourier_representations_derivative}, and \eqref{fourier_representation_linear_operator} in \eqref{functional_WNE_zeroth_order}, we get, for the first term of the RHS:
\begin{gather}
-\int\limits_{\mathcal{T}}\frac{\delta}{\delta \zeta(x)}\left\{L[\zeta(x,t)]P(\zeta,t)\right\}dx\nonumber\\
= -\int\limits_{\mathcal{T}}\sum\limits_{k}e^{-ikx}\frac{\partial}{\partial \zeta_k}\{\sum\limits_{n}e^{inx}L_n\zeta_nP\}dx\nonumber\\
= -\int\limits_{\mathcal{T}}\sum\limits_{k}\sum\limits_{n}e^{-i(k-n)x}\frac{\partial}{\partial \zeta_k}\{L_n\zeta_nP\}dx\nonumber\\
= -2\pi\sum\limits_{k}L_{k}\frac{\partial}{\partial \zeta_k}\{\zeta_kP\}\label{fourier_FPE_first_term}
\end{gather}
and for the second:
\begin{gather}
\int\limits_{\mathcal{T}}\sum\limits_{k}e^{ikx}A_k\left(\sum\limits_{m}\sum\limits_{n}e^{-i(m+n)x}\frac{\partial}{\partial \zeta_m}\frac{\partial}{\partial \zeta_n}P\right)dx\nonumber\\
= \int\limits_{\mathcal{T}}\sum\limits_{k}\sum\limits_{m}\sum\limits_{n}e^{i(k-m-n)x}A_k\frac{\partial}{\partial \zeta_m}\frac{\partial}{\partial \zeta_n}\{P\}dx\nonumber\\
= 2\pi\sum\limits_{m}\sum\limits_{n}A_{m+n}\frac{\partial}{\partial \zeta_m}\frac{\partial}{\partial \zeta_{n}}\{P\}\label{fourier_FPE_second_term}
\end{gather}
Substituting \eqref{fourier_FPE_first_term} and \eqref{fourier_FPE_second_term} into \eqref{functional_FPE}, we see that the Fokker-Planck equation in Fourier space reads:
\begin{equation}
\label{fourier_FPE}
\frac{\partial P}{\partial t} = -2\pi\sum\limits_{k}L_{k}\frac{\partial}{\partial \zeta_k}\{\zeta_kP\} + \pi\sum\limits_{m}\sum\limits_{n}A_{m+n}\frac{\partial}{\partial \zeta_m}\frac{\partial}{\partial \zeta_{n}}\{P\}
\end{equation}
It is important to remember that since $\zeta(x,t)$ is a stochastic process, $\zeta_i$ is really a stochastic process and thus $\zeta_i(t)$ is actually shorthand for the random variable $(\zeta_i)_{t}(\omega)$, where $\omega$ is a sample path in the Fourier dual of our original probability space. Multiplying both sides of \eqref{fourier_FPE} by $\zeta_r$ and integrating over the probability space to obtain expectation values, we see that
\begin{align}
\frac{d}{dt}\mathbb{E}[\zeta_r] &= - 2\pi \sum\limits_{k}\int\zeta_rL_k\frac{\partial}{\partial \zeta_k}\{\zeta_k P\}d\omega + \pi\sum\limits_{m}\sum\limits_{n}A_{m+n}\int\zeta_r\frac{\partial}{\partial \zeta_m}\frac{\partial}{\partial \zeta_{n}}(P)d\omega\nonumber\\
&=  2\pi \sum\limits_{k}L_k\int\zeta_k\frac{\partial \zeta_r}{\partial \zeta_k}Pd\omega + \pi\sum\limits_{m}\sum\limits_{n}A_{m+n}\int\frac{\partial^2 \zeta_r}{\partial \zeta_m\partial \zeta_{n}}Pd\omega\nonumber\\
&=  2\pi L_{r}\mathbb{E}[\zeta_r]\label{fourier_mode_mean}
\end{align}
where we have used integration by parts and neglected the boundary term in the second step (assuming once again that $P$ decays rapidly enough near the boundaries that this is doable), and then used \eqref{fourier_mode_relation} to arrive at the final expression. Similarly, multiplying \eqref{fourier_FPE} by $\zeta_r\zeta_s$, integrating over the probability space and using integration by parts, we get:
\begin{align}
\frac{d}{dt}\mathbb{E}[\zeta_r\zeta_s] &= 2\pi \sum\limits_{k}L_{k}\int\zeta_kP\frac{\partial}{\partial \zeta_k}\{\zeta_r\zeta_s\}d\omega + \pi\sum\limits_{m}\sum\limits_{n}A_{m+n}\int\limits_{-\infty}^{\infty}P\frac{\partial}{\partial \zeta_m}\frac{\partial}{\partial \zeta_{n}}\{\zeta_r\zeta_s\}d\omega\nonumber\\
&= 2\pi (L_{r} + L_{s})\mathbb{E}[\zeta_r\zeta_s] + \pi (A_{2r}+A_{2s})\label{fourier_mode_covariance}
\end{align}
At the stationary state, the LHS must be zero by definition, and we must therefore have, for every $r,s \in \mathbb{Z}$,:
\begin{equation}
\label{fourier_mode_covariance_stationary}
\mathbb{E}[\zeta_r\zeta_s] = -   \frac{A_{2r}+A_{2s}}{2(L_{r}+L_{s})}
\end{equation}
Recall that the Fourier modes of any real function $\varphi$ must satisfy $\varphi_{-r} = \overline{\varphi}_r$. Since $\zeta$, $A$ and $L$ are all real, we can substitute $s=-r$ in equation \eqref{fourier_mode_covariance_stationary} to obtain the autocovariance relation:
\begin{equation}
\label{fourier_mode_autocovariance}
\mathbb{E}[|\zeta_r|^2] =- \frac{\mathrm{Re}(A_{2r})}{2\mathrm{Re}(L_{r})}
\end{equation}

The presence of phenotypic clustering can be detected using the `spatial covariance' of our original process $\phi$, defined as \citep{rogers_demographic_2012}:
\begin{equation}
\label{spatial_covariance_defn}
\Xi[x] = m(\mathcal{T})\int\limits_{\mathcal{T}}\mathbb{E}[\phi_{\infty}(x)\phi_{\infty}(y-x)]dy
\end{equation}
where $\phi_{\infty}$ is the stationary state distribution of $\{\phi_t\}_{t}$ and $m$ is the Lebesgue measure. We can use a spatial analogue of the Wiener-Khinchin theorem to calculate:
\begin{equation}
\label{spatial_covariance_zeta}
\Xi[x] = m(\mathcal{T})\left[\int\limits_{\mathcal{T}}\psi_{\infty}(x)\psi_{\infty}(y-x)dy + \frac{1}{K}\sum\limits_{r=-\infty}^{\infty}\mathbb{E}[|\zeta_r|^2]e^{irx}\right]
\end{equation}
where the expectations in the second term are for the stationary state. A flat $\Xi[x]$ indicates that there are no clusters, and peaks indicate the presence of clusters.

\subsection{An example: The quantitative logistic equation}

As an example, let us carry out the functional Kramers-Moyal expansion for the birth and death functionals given by \eqref{Rogers_logistic_BD}. In terms of the scaled variable $\phi = K\nu$, these functions read:
\begin{equation}
\label{Rogers_logistic_BD_scaled}
\begin{aligned}
b_K(x|\phi) &= \frac{1}{K}b(x|\nu) = \frac{1}{K}\left( r\int\limits_{\mathcal{T}}m(x,y)K\phi(y)dy\right)\\
    d_K(x|\phi) &= \frac{1}{K}d(x|\nu) =  \frac{1}{K}\left(\frac{K\phi(x)}{Kn(x)}\int\limits_{\mathcal{T}}\alpha(x,y)K\phi(y)dy\right)
\end{aligned}
\end{equation}
Thus, using equation \eqref{deterministic_traj}, the deterministic trajectory becomes:
\begin{equation}
\label{Rogers_logistic_BD_deterministic}
\frac{\partial \psi}{\partial t}(x,t) = r\int\limits_{\mathcal{T}}m(x,y)\psi(y,t)dy-\frac{1}{n(x)}\psi(x,t)\int\limits_{\mathcal{T}}\alpha(x,y)\psi(y,t)dy
\end{equation}
Note that if we employ the change of variables $\Psi = K\psi$ to go back from $\mathcal{M}_{K}$ (\textit{i.e} $\phi^{(t)}$) to $\mathcal{M}$ (\textit{i.e} $\nu^{(t)}$), we recover the familiar continuous logistic equation (Equation \eqref{cts_logistic}) as the deterministic limit:
\begin{align*}
\frac{\partial \Psi}{\partial t}(x,t) &= r\int\limits_{\mathcal{T}}m(x,y)\Psi(y,t)dy-\frac{\Psi(x,t)}{Kn(x)}\int\limits_{\mathcal{T}}\alpha(x,y)\Psi(y,t)dy \\
&\approx r\Psi(x,t) -\frac{\Psi(x,t)}{K(x)}\int\limits_{\mathcal{T}}\alpha(x,y)\Psi(y,t)dy + D_m\nabla^2_{x}\Psi(x,t)
\end{align*}
where $K(x) = Kn(x)$ is the carrying capacity experienced by an individual of phenotype $x$, and $D_m = r \sigma_m^2/2$ measures the `diffusion rate' of the population in trait space. It is left as an exercise for the reader to verify by the same steps that if we instead have the birth rate functional $b(x|\phi) = \lambda\int m(x,y)\phi(y)dy$ (with $m(x,y)$ as defined in \eqref{Rogers_logistic_BD}) and the death rate functional $d(x|\phi) = \phi(x)\left(\mu+(\lambda-\mu)\phi(x)/K\right)$, the macroscopic limit yields the famous Fisher-KPP equation with growth rate $r=\lambda-\mu$ and diffusion constant $D = \lambda \sigma_m^2/2$.\\
\\
In any case, for the system defined by \eqref{Rogers_logistic_BD_scaled}, we can also calculate $\mathcal{D}_{\zeta}[\mathcal{A}^-]$ as
\begin{align*}
\mathcal{D}_{\zeta}[\mathcal{A}^-] &= \frac{d}{d\epsilon}\left( r\int\limits_{\mathcal{T}} m(x,y)(\psi(y)+\epsilon\zeta(y))dy - \frac{\psi(x)+\epsilon\zeta(x)}{n(x)}\int\limits_{\mathcal{T}}\alpha(x,y)(\psi(y)+\epsilon\zeta(y))dy\right) \biggl{|}_{\epsilon = 0}\\
&= r\int\limits_{\mathcal{T}}m(x,y)\zeta(y)dy - \frac{1}{n(x)}\left(\psi(x)\int\limits_{\mathcal{T}}\alpha(x,y)\zeta(y)dy + \zeta(x)\int\limits_{\mathcal{T}}\alpha(x,y)\psi(y)dy\right)
\end{align*}